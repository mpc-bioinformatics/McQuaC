{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std imports\n",
    "from typing import Optional\n",
    "\n",
    "# 3rd party imports\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text, bindparam\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#############\n",
    "# parameters\n",
    "\n",
    "raw_files = [\"OEI06439\", \"OEI06441\",\"OEI06443\",\"OEI06445\",\"OEI06447\",\"OEI06449\",\"OEI06453\",\"OEI06455\",\"OEI06459\",\"OEI06461\",\"OEI06463\",\"OEI06465\",\"OEI06467\"\n",
    "    \"OEI06469\",\"OEI06471\",\"OEI06473\",\"OEI06475\",\"OEI06477\",\"OEI06481\",\"OEI06483\",\"OEI06485\",\"OEI06487\",\"OEI06489\",\"OEI06491\",\"OEI06493\",\"OEI06495\",\"OEI06497\",\n",
    "    \"OEI06499\",\"OEI06504\",\"OEI06506\",\"OEI06508\",\"OEI06510\",\"OEI06518\",\"OEI06520\",\"OEI06522\",\"OEI06526\",\"OEI06528\",\"OEI06530\"]\n",
    "\n",
    "print(raw_files)\n",
    "\n",
    "\n",
    "##########\n",
    "\n",
    "engine = create_engine(\"mysql+mariadbconnector://mpcqc:quality@mpc-qc/mpcqc\")\n",
    "\n",
    "\n",
    "file_df: Optional[pd.DataFrame] = None\n",
    "with engine.connect() as conn:\n",
    "    statement = text(\"SELECT * FROM files WHERE filename IN :raw_files LIMIT 100\")\n",
    "    statement = statement.bindparams(\n",
    "        bindparam(\"raw_files\", tuple(raw_files), expanding=True)\n",
    "    )\n",
    "    #print(statement.compile(compile_kwargs={\"literal_binds\": True}))\n",
    "    query = conn.execute(statement)\n",
    "    file_df = pd.DataFrame(query.fetchall(), columns=query.keys())\n",
    "\n",
    "print(file_df)\n",
    "\n",
    "ids = file_df[\"id\"]\n",
    "#print(ids)\n",
    "#print(tuple(ids))\n",
    "\n",
    "run_df: Optional[pd.DataFrame] = None\n",
    "with engine.connect() as conn:\n",
    "    statement = text(\"SELECT * FROM run_data WHERE fileID IN :ids LIMIT 100\")\n",
    "    statement = statement.bindparams(\n",
    "        bindparam(\"ids\", tuple(ids), expanding=True)\n",
    "    )\n",
    "    print(statement.compile(compile_kwargs={\"literal_binds\": True}))\n",
    "    query = conn.execute(statement)\n",
    "    run_df = pd.DataFrame(query.fetchall(), columns=query.keys())\n",
    "\n",
    "\n",
    "\n",
    "feature_df: Optional[pd.DataFrame] = None\n",
    "with engine.connect() as conn:\n",
    "    statement = text(\"SELECT * FROM feature_data WHERE fileID IN :ids LIMIT 100\")\n",
    "    statement = statement.bindparams(\n",
    "        bindparam(\"ids\", tuple(ids), expanding=True)\n",
    "    )\n",
    "    query = conn.execute(statement)\n",
    "    feature_df = pd.DataFrame(query.fetchall(), columns=query.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ident_df: Optional[pd.DataFrame] = None\n",
    "with engine.connect() as conn:\n",
    "    statement = text(\"SELECT * FROM identification_data WHERE fileID IN :ids LIMIT 100\")\n",
    "    statement = statement.bindparams(\n",
    "        bindparam(\"ids\", tuple(ids), expanding=True)\n",
    "    )\n",
    "    query = conn.execute(statement)\n",
    "    ident_df = pd.DataFrame(query.fetchall(), columns=query.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(file_df)\n",
    "\n",
    "#print(run_df)\n",
    "\n",
    "#print(feature_df)\n",
    "\n",
    "#print(ident_df)\n",
    "\n",
    "\n",
    "join1 = file_df.set_index('id').join(run_df.set_index('fileID'), on='id')\n",
    "#print(join1)\n",
    "\n",
    "\n",
    "join1 = file_df.merge(run_df, left_on='id', right_on='fileID')\n",
    "#print(join1)\n",
    "\n",
    "join2 = join1.merge(feature_df, left_on='id', right_on='fileID')\n",
    "#print(join2)\n",
    "\n",
    "join_df = join2.merge(ident_df, left_on='id', right_on='fileID')\n",
    "#print(join_df)\n",
    "\n",
    "print(join_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: total nr of MS1 and MS2\n",
    "df_pl1 = join_df[[\"id\", \"filename\", \"total_nr_MS1\", \"total_nr_MS2\"]]\n",
    "df_pl1_long = df_pl1.melt(id_vars = [\"id\", \"filename\"])\n",
    "#print(df_pl1_long)\n",
    "#df_pl1_long = df_pl1_long.reset_index(level=[\"level\"])\n",
    "\n",
    "fig1 = px.bar(df_pl1_long, x=\"filename\", y=\"value\", color=\"variable\", barmode = \"group\")\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Barplot PSMs, peptides, proteins\n",
    "df_pl2 = join_df[[\"id\", \"filename\", \"number-filtered-psms\", \"number-filtered-peptides\", \"number-filtered-protein-groups\", \"identified_nr_features\"]]\n",
    "df_pl2_long = df_pl2.melt(id_vars = [\"id\", \"filename\"])\n",
    "#print(df_pl2_long)\n",
    "#df_pl2_long = pd.wide_to_long(df_pl2, stubnames = 'total_nr', i = ['id'], j = 'level', sep='_', suffix=r'\\w+')\n",
    "#df_pl2_long = df_pl2_long.reset_index(level=[\"level\"])\n",
    "\n",
    "fig2 = px.bar(df_pl2_long, x=\"filename\", y=\"value\", color=\"variable\", barmode = \"group\")\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Figure 3 TIC Overlay\n",
    "\n",
    "MS1_TICs = join_df[\"MS1-TIC-data\"]\n",
    "MS1_TICs[0]\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "TIC_list = []\n",
    "\n",
    "for index in join_df.index:\n",
    "    bio = BytesIO(MS1_TICs[index])\n",
    "    print(bio)\n",
    "\n",
    "    tic = None\n",
    "    with zipfile.ZipFile(bio, \"r\") as zip_ref:\n",
    "        for name in zip_ref.namelist():\n",
    "            tic = pd.read_csv(BytesIO(zip_ref.read(name)), sep=\",\")\n",
    "            tic[\"filename\"] = join_df[\"filename\"][index]\n",
    "            TIC_list.append(tic)\n",
    "\n",
    "\n",
    "    #print(tic)\n",
    "\n",
    "TIC_list = pd.concat(TIC_list)\n",
    "\n",
    "#bio = BytesIO(MS1_TICs[0])\n",
    "\n",
    "\n",
    "\n",
    "print(TIC_list)\n",
    "\n",
    "fig3 = px.line(TIC_list, x=\"scan_start_time\", y=\"total_ion_current\", color='filename')\n",
    "fig3.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4: Barplot TIC quantiles\n",
    "df_pl4 = join_df[[\"id\", \"filename\", 'RT-TIC-Q1', 'RT-TIC-Q2', 'RT-TIC-Q3', 'RT-TIC-Q4']]\n",
    "df_pl4_long = df_pl4.melt(id_vars = [\"id\", \"filename\"])\n",
    "\n",
    "fig4 = px.bar(df_pl4_long, x=\"filename\", y=\"value\", color=\"variable\")\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5: Barplot MS1 TIC quantiles\n",
    "df_pl5 = join_df[[\"id\", \"filename\", 'RT-MS1-Q1', 'RT-MS1-Q2', 'RT-MS1-Q3', 'RT-MS1-Q4']]\n",
    "df_pl5_long = df_pl5.melt(id_vars = [\"id\", \"filename\"])\n",
    "\n",
    "fig5 = px.bar(df_pl5_long, x=\"filename\", y=\"value\", color=\"variable\")\n",
    "fig5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 6: Barplot MS2 TIC quantiles\n",
    "df_pl6 = join_df[[\"id\", \"filename\", 'RT-MS2-Q1', 'RT-MS2-Q2', 'RT-MS2-Q3', 'RT-MS2-Q4']]\n",
    "df_pl6_long = df_pl6.melt(id_vars = [\"id\", \"filename\"])\n",
    "\n",
    "fig6 = px.bar(df_pl6_long, x=\"filename\", y=\"value\", color=\"variable\")\n",
    "fig6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 7: Precursor charge\n",
    "df_pl7 = join_df[[\"id\", \"filename\", 'MS2-PrecZ-1', 'MS2-PrecZ-2', 'MS2-PrecZ-3', 'MS2-PrecZ-4', 'MS2-PrecZ-5', 'MS2-PrecZ-more']]\n",
    "df_pl7_long = df_pl7.melt(id_vars = [\"id\", \"filename\"])\n",
    "\n",
    "fig7 = px.bar(df_pl7_long, x=\"filename\", y=\"value\", color=\"variable\")\n",
    "fig7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 8: PSM charge states (of identified spectra)\n",
    "df_pl8 = join_df[[\"id\", \"filename\", 'psmZ-1', 'psmZ-2', 'psmZ-3', 'psmZ-4', 'psmZ-5']]\n",
    "df_pl8_long = df_pl8.melt(id_vars = [\"id\", \"filename\"])\n",
    "\n",
    "fig8 = px.bar(df_pl8_long, x=\"filename\", y=\"value\", color=\"variable\")\n",
    "fig8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 9: Missed cleavages\n",
    "df_pl9 = join_df[[\"id\", \"filename\", 'psm-missed-0', 'psm-missed-1', 'psm-missed-2', 'psm-missed-3']]\n",
    "df_pl9_long = df_pl9.melt(id_vars = [\"id\", \"filename\"])\n",
    "\n",
    "fig9 = px.bar(df_pl9_long, x=\"filename\", y=\"value\", color=\"variable\")\n",
    "fig9.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 10 PCA on all data\n",
    "\n",
    "df_pl10 = join_df[[\"RT_duration\", \n",
    "\"total_nr_MS1\",\n",
    "\"total_nr_MS2\", \n",
    "\"RT-TIC-Q1\",\n",
    "\"RT-TIC-Q2\",\n",
    "\"RT-TIC-Q3\",\n",
    "\"RT-TIC-Q4\",\n",
    "\"RT-MS1-Q1\",\n",
    "\"RT-MS1-Q2\",\n",
    "\"RT-MS1-Q3\",\n",
    "\"RT-MS1-Q4\",\n",
    "\"RT-MS2-Q1\",\n",
    "\"RT-MS2-Q2\", \n",
    "\"RT-MS2-Q3\",\n",
    "\"RT-MS2-Q4\", \n",
    "\"MS1-TIC-Change-Q2\",\n",
    "\"MS1-TIC-Change-Q3\", \n",
    "\"MS1-TIC-Change-Q4\",\n",
    "\"MS1-TIC-Q2\",\n",
    "\"MS1-TIC-Q3\",\n",
    "\"MS1-TIC-Q4\", \n",
    "\"MS1-Freq-Max\",\n",
    "\"MS1-Density-Q1\",\n",
    "\"MS1-Density-Q2\", \n",
    "\"MS1-Density-Q3\",\n",
    "\"MS2-Freq-Max\",\n",
    "\"MS2-Density-Q1\",\n",
    "\"MS2-Density-Q2\", \n",
    "\"MS2-Density-Q3\",\n",
    "\"MS2-PrecZ-1\", \n",
    "\"MS2-PrecZ-2\", \n",
    "\"MS2-PrecZ-3\",\n",
    "\"MS2-PrecZ-4\",\n",
    "\"MS2-PrecZ-5\",\n",
    "\"MS2-PrecZ-more\", \n",
    "\"accumulated_MS1_TIC\", \n",
    "\"accumulated_MS2_TIC\",\n",
    "\"identified_nr_features\",\n",
    "\"FeatureZ-1\",\n",
    "\"FeatureZ-2\",\n",
    "\"FeatureZ-3\",\n",
    "\"FeatureZ-4\",\n",
    "\"FeatureZ-5\", \n",
    "\"psmZ-1\",\n",
    "\"psmZ-2\", \n",
    "\"psmZ-3\", \n",
    "\"psmZ-4\", \n",
    "\"psmZ-5\"]]\n",
    "\n",
    "#print(df_pl10)\n",
    "\n",
    "#import sklearn\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "df_pl10_norm = pd.DataFrame(StandardScaler().fit_transform(df_pl10)) \n",
    "#print(df_pl10_norm)\n",
    "\n",
    "\n",
    "#perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "print(pca)\n",
    "\n",
    "principalComponents = pca.fit_transform(df_pl10_norm)\n",
    "\n",
    "print(principalComponents)\n",
    "\n",
    "col = range(1,(principalComponents.shape[1]+1))\n",
    "col = ['pca'+ str(y) for y in col]\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = col)\n",
    "print(principalDf.head())\n",
    "\n",
    "#explained variance\n",
    "#pca_var =pca.explained_variance_ratio_\n",
    "#print(pca_var)\n",
    "#pca_var[0:2].sum()\n",
    "#print(\"\\n The explained variance of the two first principal components combined is\", pca_var[0:2].sum(),\"!\")\n",
    "\n",
    "fig10 = px.scatter(principalDf, x=\"pca1\", y=\"pca2\")\n",
    "fig10.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 11 PCA on raw data\n",
    "\n",
    "df_pl11 = join_df[[\"RT_duration\", \n",
    "\"total_nr_MS1\",\n",
    "\"total_nr_MS2\", \n",
    "\"RT-TIC-Q1\",\n",
    "\"RT-TIC-Q2\",\n",
    "\"RT-TIC-Q3\",\n",
    "\"RT-TIC-Q4\",\n",
    "\"RT-MS1-Q1\",\n",
    "\"RT-MS1-Q2\",\n",
    "\"RT-MS1-Q3\",\n",
    "\"RT-MS1-Q4\",\n",
    "\"RT-MS2-Q1\",\n",
    "\"RT-MS2-Q2\", \n",
    "\"RT-MS2-Q3\",\n",
    "\"RT-MS2-Q4\", \n",
    "\"MS1-TIC-Change-Q2\",\n",
    "\"MS1-TIC-Change-Q3\", \n",
    "\"MS1-TIC-Change-Q4\",\n",
    "\"MS1-TIC-Q2\",\n",
    "\"MS1-TIC-Q3\",\n",
    "\"MS1-TIC-Q4\", \n",
    "\"MS1-Freq-Max\",\n",
    "\"MS1-Density-Q1\",\n",
    "\"MS1-Density-Q2\", \n",
    "\"MS1-Density-Q3\",\n",
    "\"MS2-Freq-Max\",\n",
    "\"MS2-Density-Q1\",\n",
    "\"MS2-Density-Q2\", \n",
    "\"MS2-Density-Q3\",\n",
    "\"MS2-PrecZ-1\", \n",
    "\"MS2-PrecZ-2\", \n",
    "\"MS2-PrecZ-3\",\n",
    "\"MS2-PrecZ-4\",\n",
    "\"MS2-PrecZ-5\",\n",
    "\"MS2-PrecZ-more\", \n",
    "\"accumulated_MS1_TIC\", \n",
    "\"accumulated_MS2_TIC\"]]\n",
    "\n",
    "df_pl11_norm = pd.DataFrame(StandardScaler().fit_transform(df_pl11)) \n",
    "\n",
    "#perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "principalComponents = pca.fit_transform(df_pl11_norm)\n",
    "\n",
    "col = range(1,(principalComponents.shape[1]+1))\n",
    "col = ['pca'+ str(y) for y in col]\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = col)\n",
    "\n",
    "fig11 = px.scatter(principalDf, x=\"pca1\", y=\"pca2\")\n",
    "fig11.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b5889813a7c3a31d003558802b3b4f3490bc76b28cff89df6e28186e0cab616"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
