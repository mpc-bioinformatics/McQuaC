#!/usr/bin/env python

import json
import csv
import argparse
import base64
import zlib
import pickle
import pandas as pd

def argparse_setup():
    parser = argparse.ArgumentParser()
    parser.add_argument("-itrfp_json", help="XIC extraction in JSON format (e.g. generated by the ThermoRawFileParser)")
    parser.add_argument("-iidentifications", help="Identifications found for the sequences of teh spiek-ins")
    parser.add_argument("-ispikeins", help="The spike-ins (in CSV)")
    parser.add_argument("-ocsv", help="The metrics in CSV")

    return parser.parse_args()
if __name__ == "__main__":

    args = argparse_setup()

    # load XICs
    with open(args.itrfp_json, "r") as trfp_in:
        xics = json.load(trfp_in)
    
    # load identifications
    identifications = dict()
    with open(args.iidentifications, "r") as ids_in:
        for l in ids_in:
            cols = l[:-1].split(",")
            identifications[cols[0]] = cols[1]
    
    # load spike_ins
    comment_to_data = dict()
    with open(args.ispikeins, "r") as in_csv_file:
        # Read spike-ins CSV and get header indicies
        csv_in = csv.reader(in_csv_file)
        header = next(csv_in)
        name_idx = header.index("name")
        seq_idx = header.index("sequence")
        mz_idx = header.index("mz")
        rt_idx = header.index("RT")

        # go line-wise through the spike-ins CSV
        for l in csv_in:
            # are there any identifications for this spike-in
            nr_ids = 0
            if str(l[seq_idx]) in identifications.keys():
                nr_ids = identifications[str(l[seq_idx])]

            # map from the comment to what we need
            comment_to_data[str(l[name_idx])] = {
                "maximum_int" : -1,
                "rt_at_maximum" : -1,
                "identifications" : nr_ids,
                "expected_rt": float(l[rt_idx]),
                "delta_rt": 0,
                "expected_mz": float(l[mz_idx])
            }

    # go through the extracted XICs and try to set the data (if XIC was successfully extracted)
    for xic in xics["Content"]:
        comment = str(xic["Meta"]["Comment"])
        if comment in comment_to_data.keys():

            rts = xic["RetentionTimes"]
            intensities = xic["Intensities"]

            # default value if no intensities are found
            max_int = 0
            max_int_rt = -1

            if len(intensities) > 0:
                max_int = max(intensities)
                max_int_rt = rts[intensities.index(max_int)] * 60

            comment_to_data[comment]["rt_at_maximum"] = max_int_rt
            comment_to_data[comment]["maximum_int"] = max_int
            comment_to_data[comment]["delta_rt"] = max_int_rt - comment_to_data[comment]["expected_rt"]
    
    # prepare output
    data_out = dict()
    for comment, data in comment_to_data.items():
        spikeident = f"SPIKE_{comment}_MZ_{data['expected_mz']:.4f}_RT_{data['expected_rt']:.0f}"
        data_out[f"{spikeident}_Maximum_Intensity"] = str(data['maximum_int'])
        data_out[f"{spikeident}_RT_at_Maximum_Intensity"] = str(data['rt_at_maximum'])
        data_out[f"{spikeident}_PSMs"] = str(data['identifications'])
        data_out[f"{spikeident}_Delta_to_expected_RT"] = str(data['delta_rt'])
    
    # Pickle the final table and create a dataframe with only one column and one line
    final_table_pickled = base64.b64encode(zlib.compress(pickle.dumps(data_out), level=9)).decode("utf-8")
    final_table_pickled = {"SPIKEINS_____pickle_zlib": final_table_pickled}
    final_table_pickled = pd.DataFrame(final_table_pickled, index=[0])

    # Save to csv
    final_table_pickled.to_csv(args.ocsv, index = False)
